{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ece3e7-35b4-43c9-9d17-f67b5b2d62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a803c8b-c111-4866-ae63-693dc43a3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_reseñas(fichero_csv, carpeta_objetivo):\n",
    "    \"\"\"\n",
    "    Procesa las reseñas de un fichero CSV con etiquetas de sentimiento,\n",
    "    elimina etiquetas `<br /><br />` y guarda cada reseña en un archivo independiente\n",
    "    dentro de una carpeta objetivo.\n",
    "\n",
    "    Args:\n",
    "        fichero_csv (str): Ruta al fichero CSV con las reseñas.\n",
    "        carpeta_objetivo (str): Ruta a la carpeta donde se guardarán los archivos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Expresión regular para eliminar etiquetas `<br /><br />`\n",
    "    regex_br = re.compile(r\"<br\\s*/?>\")\n",
    "\n",
    "    with open(fichero_csv, \"r\", encoding=\"utf-8\") as f_csv, open(\"log.txt\", \"w\", encoding=\"utf-8\") as f_log:\n",
    "        reader = csv.reader(f_csv, delimiter=\",\")\n",
    "        next(reader)  # Skip header row\n",
    "\n",
    "        for idx, row in enumerate(reader, start=1):\n",
    "            # Texto de la reseña\n",
    "            review, sentiment = row\n",
    "\n",
    "            # Eliminar etiquetas\n",
    "            review_sin_br = regex_br.sub(\"\", review)\n",
    "\n",
    "            # Construir nombre de archivo con índice, sentimiento y extensión\n",
    "            filename = f\"{carpeta_objetivo}/{idx}{sentiment}.txt\"\n",
    "\n",
    "            try:\n",
    "                with open(filename, \"w\", encoding=\"utf-8\") as f_out:\n",
    "                    f_out.write(review_sin_br)\n",
    "            except Exception as e:\n",
    "                f_log.write(f\"Error al procesar reseña {idx}: {e}\\n\")\n",
    "\n",
    "fichero_csv = \"IMDB Dataset.csv\"\n",
    "carpeta_objetivo = \"script\"\n",
    "\n",
    "#procesar_reseñas(fichero_csv, carpeta_objetivo)\n",
    "\n",
    "\n",
    "\n",
    "def get_word(fichero_csv, palabra1, palabra2):\n",
    "    dictionary = dict()\n",
    "    dictionary[palabra1] = []\n",
    "    dictionary[palabra2] = []\n",
    "    dictionary[f\"{palabra1}-{palabra2}\"] = []\n",
    "\n",
    "\n",
    "    with open(fichero_csv, newline='', encoding=\"utf-8\") as csvfile:\n",
    "        i = 0\n",
    "        for linea in csvfile:\n",
    "            i += 1\n",
    "            if palabra1 in linea:\n",
    "                dictionary[palabra1].append(i)\n",
    "            if palabra2 in linea:\n",
    "                dictionary[palabra2].append(i)\n",
    "    with open(fichero_csv, newline='', encoding=\"utf-8\") as csvfile2:\n",
    "        i = 0\n",
    "        if len(dictionary[palabra1]) <= len(dictionary[palabra2]):\n",
    "            for linea in csvfile2:\n",
    "                i += 1\n",
    "                if i in dictionary[palabra1] and palabra2 in linea:\n",
    "                    dictionary[f\"{palabra1}-{palabra2}\"].append(i)\n",
    "        else:\n",
    "            for linea in csvfile2:\n",
    "                i += 1\n",
    "                if i in dictionary[palabra2] and palabra1 in linea:\n",
    "                    dictionary[f\"{palabra1}-{palabra2}\"].append(i)\n",
    "    return dictionary[f\"{palabra1}-{palabra2}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bf53930-017d-421a-b8c6-ac0d8620f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coincidences: [1, 375, 805, 2349, 5026, 5741, 6151, 6501, 6706, 8167, 10466, 11893, 14363, 15169, 15587, 15794, 19259, 19815, 20062, 20683, 22019, 22556, 25684, 26718, 28854, 29041, 29242, 30115, 31847, 33811, 34394, 34462, 35173, 37005, 37380, 39079, 39334, 39368, 39429, 40193, 40208, 42084, 42868, 43669, 45035, 45222, 45815, 46402, 46562, 46817, 47105, 47287, 47984, 48297, 49668]\n"
     ]
    }
   ],
   "source": [
    "coincidences = get_word(\"IMDB_raiz.csv\", \"brutal\", \"prison\")\n",
    "print(f\"Coincidences: {coincidences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb6344e-972d-4983-9ba1-587f3b81b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(consulta, doc):\n",
    "    #consulta: objeto que contiene la lista de palabras y que set admite como listas \n",
    "    #doc: string formado por varias palabras\n",
    "    setcon = set(consulta)\n",
    "    setdoc = set(re.findall(r\"[\\w']+\", doc))\n",
    "    coef = len(setcon.intersection(setdoc))/len(setcon.union(setdoc))\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06b5e0ff-b631-4aa5-a493-9ef706f581c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005050505050505051\n"
     ]
    }
   ],
   "source": [
    "with open(fichero_csv, newline='', encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    lines = list(reader)\n",
    "    doc = lines[coincidences[0]][0]\n",
    "    consulta = ['brutal', 'prison']\n",
    "    print(Jaccard(consulta, doc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
