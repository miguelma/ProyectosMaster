{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with a LSTM\n",
    "\n",
    "We are going to implement a LSTM in Keras. The first thing we need is a big amount of text to be able to learn a linguistic model. One can use any big text file. In this example we are going to be using El Quijote. Our model will learn a specific model based on the writting style of Cervantes in this particular book.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First we are going to dowload the corpus and convert it to lower case letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "from keras import layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = keras.utils.get_file(\n",
    "    'quijote.txt',\n",
    "    origin='https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Longitud del corpus:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del corpus: 1038397\n"
     ]
    }
   ],
   "source": [
    "encoding = sys.getfilesystemencoding()\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'quijote.txt',\n",
    "    origin='https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt')\n",
    "\n",
    "with open(path, 'r', encoding=encoding) as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print('Longitud del corpus:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will extract sentences with a partial overlapping of lenght `maxlon`, we will transform them into a one-hot vector and we will then store it in a 3D numpy array `x` whose structure will correspond to `n_sentences, maxlon, unique_characters`.\n",
    "Simultanously we will prepare a `y` array containing the corresponding targets: the one-hot vectors with the characters coming right after the extracted sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 346113\n",
      "Unique characters: 65\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlon = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlon, step):\n",
    "    sentences.append(text[i: i + maxlon])\n",
    "    next_chars.append(text[i + maxlon])\n",
    "print('Number of sentences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlon, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Our net is just one single `LSTM`followed by a `dense` classifier and a softmax for all the possible characters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitsLSTM = 100\n",
    "unitsDense = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\migue\\miniconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(unitsLSTM,input_shape=(maxlon, len(chars)))) \n",
    "model.add(layers.Dense(units = unitsDense, activation = \"relu\")) \n",
    "model.add(layers.Dense(units = unitsDense, activation = \"relu\")) \n",
    "model.add(layers.Dense(units = len(chars) , activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot vectors, we will use `categorical_crossentropy` as loss function of our model. Use RMP prop as optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer = keras.optimizers.RMSprop(0.01), \n",
    "  loss = \"categorical_crossentropy\",\n",
    "  metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and sampling from it\n",
    "\n",
    "\n",
    "Given a trained model and a text fragment as seed, we can generate a new text following these steps:\n",
    "\n",
    "*  Extract from the model the probability distribution of the given text given till that particular moment\n",
    "* Reweights the distribution for a certain \"temperature\"\n",
    "* Randomly sample the following character randomly following the reweighted distribution\n",
    "* Add the character at the end of the text\n",
    "\n",
    "With this code we reweights the original probability coming from the model and extract an index (sampling function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperatura=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperatura\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have here the loop inside of which we will do the training and generate the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "2705/2705 [==============================] - 269s 100ms/step - loss: 1.7597 - accuracy: 0.4420\n",
      "--- Generating with the following seed: \"endo que duraba algún tanto el silencio, determinaron de sa\"\n",
      "------ Temperature: 0.3\n",
      "endo que duraba algún tanto el silencio, determinaron de sancho es que te a los carme cante que el maneste de en el venteros en el cantes en en el de escubiera el mal de mí que con el manera casín con el camino en el anda con por mi compuntar señor ballar cual caballeros en el cención a la caballeros tenga de que le de en el camino casí en el maneste a que en esta cual de suerte escombres de escuando a en en la manera de camilero en el cante el parie\n"
     ]
    }
   ],
   "source": [
    "maxep = 2 #original 20\n",
    "for epoch in range(1, maxep):\n",
    "    print('Epoch: ', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlon - 1)\n",
    "    generated_text = text[start_index: start_index + maxlon]\n",
    "    print('--- Generating with the following seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperatura in [0.3]:\n",
    "        print('------ Temperature:', temperatura)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlon, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperatura)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tasks\n",
    "\n",
    "* Use your own corpus instead of El Quijote (can be in another language)\n",
    "* Modify the loop in order to take several different temperatures (between 0.1 and 1 for instance) so that you can compare each epoch depending on the temperature\n",
    "* Train for 60 epochs\n",
    "* What do you observe in the text for the different temperatures? Which seems to be the \"best\" temperature and why?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos un corpus nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/cache/epub/1497/pg1497.txt\n",
      "1244178/1244178 [==============================] - 4s 4us/step\n",
      "Longitud del corpus: 1213674\n"
     ]
    }
   ],
   "source": [
    "encoding = sys.getfilesystemencoding()\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'pg1497.txt',\n",
    "    origin='https://www.gutenberg.org/cache/epub/1497/pg1497.txt')\n",
    "\n",
    "with open(path, 'r', encoding=encoding) as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "print('Longitud del corpus:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 404538\n",
      "Unique characters: 89\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlon = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlon, step):\n",
    "    sentences.append(text[i: i + maxlon])\n",
    "    next_chars.append(text[i + maxlon])\n",
    "print('Number of sentences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlon, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitsLSTM = 100\n",
    "unitsDense = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(unitsLSTM,input_shape=(maxlon, len(chars)))) \n",
    "model.add(layers.Dense(units = unitsDense, activation = \"relu\")) \n",
    "model.add(layers.Dense(units = unitsDense, activation = \"relu\")) \n",
    "model.add(layers.Dense(units = len(chars) , activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer = keras.optimizers.RMSprop(0.01), \n",
    "  loss = \"categorical_crossentropy\",\n",
    "  metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxep = 61 \n",
    "for epoch in range(1, maxep):\n",
    "    print('Epoch: ', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlon - 1)\n",
    "    generated_text = text[start_index: start_index + maxlon]\n",
    "    print('--- Generating with the following seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperatura in [0.1,0.3,0.9]:\n",
    "        print('------ Temperature:', temperatura)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlon, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperatura)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare each epoch depending on the temperature\n",
    "#una temperatura baja hace que los caracteres más probables segun la distribucion de probabilidad calculada por el modelo\n",
    "#tengan mas relevancia, por lo que el texto tiende a ser más coherente pero menos creativo. Al aumentar la tempeeratura\n",
    "#se aumenta la probabilidad de elegir caracteres que en un principio eran menos probables, aumentando la variabilidad en el texto\n",
    "#pero aumentado el riesgo de incluir texto menos coherente.\n",
    "#mejor t: depende del objetivo. en este caso parece que ... da un balance entre coherencia y originalidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
